{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "import os\n",
    "import subprocess\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(img, h, w):\n",
    "    blob = cv.dnn.blobFromImage(img, 1.0, (w, h),\n",
    "        (103.939, 116.779, 123.680), swapRB=False, crop=False)\n",
    "\n",
    "    print ('[INFO] Setting the input to the model')\n",
    "    net.setInput(blob)\n",
    "\n",
    "    print ('[INFO] Starting Inference!')\n",
    "    start = time.time()\n",
    "    out = net.forward()\n",
    "    end = time.time()\n",
    "    print ('[INFO] Inference Completed successfully!')\n",
    "\n",
    "    # Reshape the output tensor and add back in the mean subtraction, and\n",
    "    # then swap the channel ordering\n",
    "    out = out.reshape((3, out.shape[2], out.shape[3]))\n",
    "    out[0] += 103.939\n",
    "    out[1] += 116.779\n",
    "    out[2] += 123.680\n",
    "    out /= 255.0\n",
    "    out = out.transpose(1, 2, 0)\n",
    "\n",
    "    # Printing the inference time\n",
    "    if False:\n",
    "        print ('[INFO] The model ran in {:.4f} seconds'.format(end-start))\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Source for this function:\n",
    "# https://github.com/jrosebr1/imutils/blob/4635e73e75965c6fef09347bead510f81142cf2e/imutils/convenience.py#L65\n",
    "def resize_img(img, width=None, height=None, inter=cv.INTER_AREA):\n",
    "    dim = None\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    if width is None and height is None:\n",
    "        return img\n",
    "    elif width is None:\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "    elif height is None:\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "\n",
    "    resized = cv.resize(img, dim, interpolation=inter)\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models_path = './models/instance_norm/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check if there are models to be loaded and list them\n",
    "models = []\n",
    "for f in sorted(os.listdir(models_path)):\n",
    "    if f.endswith('.t7'):\n",
    "        models.append(f)\n",
    "\n",
    "if len(models) == 0:\n",
    "    raise Exception('The model path doesn\\'t contain models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./models/instance_norm/la_muse.t7\n",
      "[INFO] Loading the model...\n"
     ]
    }
   ],
   "source": [
    "# Load the neural style transfer model\n",
    "path = models_path + ('' if models_path.endswith('/') else '/')\n",
    "print (path + models[2])\n",
    "print ('[INFO] Loading the model...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_loaded_i = -1\n",
    "total_models = len(os.listdir(models_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_loaded_i = 0\n",
    "model_to_load = path + models[model_loaded_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Model Loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "net = cv.dnn.readNetFromTorch(model_to_load)\n",
    "print ('[INFO] Model Loaded successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n",
      "[INFO] Setting the input to the model\n",
      "[INFO] Starting Inference!\n",
      "[INFO] Inference Completed successfully!\n"
     ]
    }
   ],
   "source": [
    "vid = cv.VideoCapture(0)\n",
    "while True:\n",
    "    _, frame = vid.read()\n",
    "    img = resize_img(frame, width=600)\n",
    "    h, w  = img.shape[:2]\n",
    "    out = predict(img, h, w)\n",
    "\n",
    "    cv.imshow('Stylizing Real-time Video', out)\n",
    "\n",
    "    key = cv.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('n'): \n",
    "        model_loaded_i = (model_loaded_i + 1) % total_models\n",
    "        model_to_load = path + models[model_loaded_i]\n",
    "        net = cv.dnn.readNetFromTorch(model_to_load)\n",
    "    elif key == ord('p'):\n",
    "        model_loaded_i = (model_loaded_i - 1) % total_models\n",
    "        model_to_load = path + models[model_loaded_i]\n",
    "        net = cv.dnn.readNetFromTorch(model_to_load)\n",
    "\n",
    "vid.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
